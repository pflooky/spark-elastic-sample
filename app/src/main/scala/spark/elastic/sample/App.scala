/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package spark.elastic.sample

import org.apache.spark.sql.SparkSession
import org.elasticsearch.spark.sql.sparkDatasetFunctions

object App {
  def main(args: Array[String]): Unit = {
    println(greeting())
    val ss = createSparkSession()
    val people = Seq(Person("Peter", 27, "pflook@email.com"))
    import ss.implicits._
    ss.createDataset(people).toDF().saveToEs("my-index")
  }

  def greeting(): String = "Hello, world!"

  def createSparkSession(): SparkSession = {
    SparkSession.builder()
      .master("local[1]")
      .appName("spark-elastic-app")
      .config("spark.hadoop.es.nodes", "localhost")
      .config("spark.hadoop.es.port", "9200")
      .config("spark.hadoop.es.resource", "my-index")
      .getOrCreate()
  }
}

case class Person(name: String, age: Int, email: String)
